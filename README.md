# ğŸš€ Parallel Matrix Benchmark: CPU vs GPU

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://python.org)
[![CUDA](https://img.shields.io/badge/CUDA-12.x-green.svg)](https://developer.nvidia.com/cuda-toolkit)
[![GPU](https://img.shields.io/badge/GPU-RTX%203070%20Ti-success.svg)](https://www.nvidia.com/en-us/geforce/graphics-cards/30-series/rtx-3070-ti/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

## ğŸ“‹ Sobre o Projeto

Este projeto implementa um **benchmark completo** para comparar o desempenho de processamento paralelo de matrizes entre diferentes configuraÃ§Ãµes de **CPU** e **GPU CUDA**. O estudo demonstra tÃ©cnicas de programaÃ§Ã£o paralela e analisa o ponto de break-even onde a aceleraÃ§Ã£o por GPU supera o processamento CPU tradicional.

**Desenvolvido como trabalho acadÃªmico para:** *AceleraÃ§Ã£o em CiÃªncia de Dados usando ComputaÃ§Ã£o Paralela*

### ğŸ† Resultados Principais
- **Break-even Point**: GPU vence a partir de matrizes **2000x2000**
- **MÃ¡ximo Speedup GPU**: **9.5x** mais rÃ¡pida que CPU (matriz 3000x3000)
- **CPU Melhor ConfiguraÃ§Ã£o**: 8 threads para matrizes pequenas/mÃ©dias
- **GPU Testada**: NVIDIA RTX 3070 Ti com CUDA 12.x

## ğŸ¯ Objetivos

- **Aplicar conceitos de paralelismo** em arquiteturas CPU e GPU
- **Comparar paradigmas** de paralelismo de memÃ³ria compartilhada (OpenMP-like) vs aceleraÃ§Ã£o por GPU (CUDA)
- **Avaliar desempenho e escalabilidade** de diferentes configuraÃ§Ãµes
- **Demonstrar speedup e eficiÃªncia** com mÃ©tricas quantificÃ¡veis

## ğŸ—ï¸ Arquitetura do Projeto

```
Paralela/
â”œâ”€â”€ matrix_cpu.py              # Benchmark CPU (1, 2, 4, 8, todas threads)
â”œâ”€â”€ matrix_gpu.py              # Benchmark GPU (CuPy, Numba CUDA)
â”œâ”€â”€ matrix_comparison.py       # ComparaÃ§Ã£o completa CPU vs GPU
â”œâ”€â”€ requirements.txt           # DependÃªncias do projeto
â””â”€â”€ README.md                 # Este arquivo
```

## ğŸ“Š ConfiguraÃ§Ãµes Testadas

### CPU (Paralelismo de MemÃ³ria Compartilhada)
- **1 thread** (sequencial - baseline)
- **2 threads** 
- **4 threads**
- **8 threads**
- **Todas as threads** disponÃ­veis (20 no seu sistema)

### ImplementaÃ§Ãµes CPU
1. **NumPy Paralelo**: Usa bibliotecas otimizadas (BLAS/LAPACK) com controle de threads
2. **ParalelizaÃ§Ã£o Manual**: Divide matriz em chunks usando `multiprocessing`

### GPU (ComputaÃ§Ã£o Acelerada)
- **CuPy**: Biblioteca NumPy-like para GPU CUDA
- **Numba CUDA**: Kernels CUDA customizados em Python

## ğŸ› ï¸ InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

### 1. DependÃªncias BÃ¡sicas
```bash
pip install -r requirements.txt
```

### 2. DependÃªncias GPU (Opcional)
Para usar aceleraÃ§Ã£o GPU, instale CuPy conforme sua versÃ£o CUDA:

```bash
# Verificar versÃ£o CUDA
nvcc --version
nvidia-smi

# CUDA 12.x
pip install cupy-cuda12x

# CUDA 11.x  
pip install cupy-cuda11x

# Sem GPU (apenas para testes)
pip install cupy-cpu
```

### 3. Verificar Sistema
```bash
# CPU
python -c "import multiprocessing; print(f'CPU Cores: {multiprocessing.cpu_count()}')"

# GPU
nvidia-smi
```

## ğŸš€ Como Executar

### Teste RÃ¡pido
```bash
# Ativa ambiente virtual
source venv/bin/activate

# Executa anÃ¡lise completa
python matrix_comparison.py
```

### AnÃ¡lise de Escalabilidade (Recomendado)
```bash
# Testa diferentes tamanhos de matriz
python test_sizes.py
```

### Benchmarks Individuais

#### CPU (Threads: 1, 2, 4, 8, 20)
```bash
python matrix_cpu.py
```

#### GPU (CUDA)
```bash
python matrix_gpu.py
```

### ğŸ“Š Arquivos Gerados
- `complete_benchmark_results.csv/png`: ComparaÃ§Ã£o geral
- `scalability_analysis.png`: AnÃ¡lise de escalabilidade  
- `cpu_benchmark_results.csv/png`: Resultados CPU detalhados
- `gpu_benchmark_results.csv/png`: Resultados GPU

## ğŸ“ˆ MÃ©tricas Avaliadas

### Speedup
```
Speedup = Tempo_Sequencial / Tempo_Paralelo
```

### EficiÃªncia
```
EficiÃªncia = Speedup / NÃºmero_de_Threads
```

### AnÃ¡lises IncluÃ­das
- **Tempo de execuÃ§Ã£o** absoluto
- **Speedup** relativo ao baseline sequencial
- **EficiÃªncia** de paralelizaÃ§Ã£o
- **Escalabilidade** (anÃ¡lise de crescimento)
- **ComparaÃ§Ã£o CPU vs GPU** (total e apenas computaÃ§Ã£o)

## ğŸ“Š Resultados Obtidos (RTX 3070 Ti)

### ğŸ” AnÃ¡lise por Tamanho de Matriz

| Tamanho | CPU (8 threads) | GPU (CUDA) | **Speedup GPU** | Vencedor |
|---------|-----------------|------------|-----------------|----------|
| 1000Ã—1000 | 0.0081s | 0.0544s | **0.15x** | ğŸ’» **CPU** |
| 2000Ã—2000 | 0.0405s | 0.0066s | **5.46x** | ğŸš€ **GPU** |
| 3000Ã—3000 | 0.1716s | 0.0181s | **9.49x** | ğŸš€ **GPU** |
| 4000Ã—4000 | 0.2941s | 0.0335s | **8.35x** | ğŸš€ **GPU** |

### ğŸ“ˆ Insights Principais

#### CPU Performance
- **Melhor configuraÃ§Ã£o**: 8 threads para a maioria dos casos
- **ParalelizaÃ§Ã£o manual**: Muito lenta devido ao overhead de multiprocessing
- **NumPy/BLAS**: Extremamente otimizado para operaÃ§Ãµes de matriz

#### GPU Performance  
- **Break-even**: 2000Ã—2000 (15.3 MB por matriz)
- **Sweet spot**: 3000Ã—3000+ para mÃ¡ximo speedup
- **Overhead crÃ­tico**: TransferÃªncia de dados para matrizes pequenas
- **Compute capability**: Consistente ~6-9x speedup para matrizes grandes

#### Descobertas Importantes
1. **CPU surpreendente**: NumPy/BLAS compete muito bem atÃ© ~2000Ã—2000
2. **Overhead GPU**: 60-70% do tempo gasto em transferÃªncias para matrizes pequenas  
3. **Escalabilidade**: GPU mantÃ©m vantagem crescente com tamanho da matriz
4. **Multiprocessing**: Manual parallelization tem overhead proibitivo vs bibliotecas otimizadas

## ğŸ”§ ConfiguraÃ§Ãµes PersonalizÃ¡veis

### Tamanho da Matriz
```python
# No cÃ³digo, modifique:
processor = MatrixProcessorCPU(matrix_size=1000)  # Para 1000x1000
processor = MatrixProcessorGPU(matrix_size=4000)  # Para 4000x4000
```

### Threads a Testar
```python
# Em matrix_cpu.py, linha ~116:
thread_configs = [1, 2, 4, 8, 16, 32]  # Personalize aqui
```

## ğŸ“ Alinhamento com Trabalho AcadÃªmico

Este projeto atende perfeitamente aos requisitos do trabalho:

### âœ… Conceitos Explorados
- **MPI-like**: ParalelizaÃ§Ã£o manual com `multiprocessing`
- **OpenMP-like**: Controle de threads NumPy/BLAS
- **CUDA**: AceleraÃ§Ã£o GPU com CuPy e Numba

### âœ… Objetivos Atendidos
- **AplicaÃ§Ã£o de paralelismo**: âœ… MÃºltiplas implementaÃ§Ãµes
- **DiferenciaÃ§Ã£o de paradigmas**: âœ… CPU vs GPU claramente separados
- **ImplementaÃ§Ã£o GPU**: âœ… CuPy e Numba CUDA
- **AvaliaÃ§Ã£o de desempenho**: âœ… MÃ©tricas quantificÃ¡veis
- **Uso de IA**: âœ… Documentado neste README

### âœ… Deliverables
- **CÃ³digo fonte**: âœ… TrÃªs arquivos principais bem documentados
- **AnÃ¡lise de desempenho**: âœ… CSV e grÃ¡ficos automÃ¡ticos
- **ComparaÃ§Ã£o**: âœ… Sequencial vs paralelo vs GPU
- **DocumentaÃ§Ã£o**: âœ… README completo

## ğŸ¤– Uso de IA no Projeto

Este projeto foi desenvolvido com assistÃªncia significativa de IA (Claude/ChatGPT) nas seguintes Ã¡reas:

### AssistÃªncia de CÃ³digo
- **EstruturaÃ§Ã£o das classes** e organizaÃ§Ã£o modular
- **ImplementaÃ§Ã£o de benchmarks** e mediÃ§Ã£o de tempo
- **ParalelizaÃ§Ã£o manual** com multiprocessing
- **IntegraÃ§Ã£o CUDA** com CuPy e Numba

### OtimizaÃ§Ã£o e Boas PrÃ¡ticas
- **Controle de threads** via variÃ¡veis de ambiente
- **Tratamento de erros** e verificaÃ§Ã£o de disponibilidade GPU
- **VisualizaÃ§Ãµes** com matplotlib e anÃ¡lise estatÃ­stica
- **DocumentaÃ§Ã£o** e comentÃ¡rios explicativos

### Debugging e ValidaÃ§Ã£o
- **VerificaÃ§Ã£o de consistÃªncia** entre resultados CPU e GPU
- **Tratamento de dependÃªncias** opcionais
- **InstalaÃ§Ã£o automÃ¡tica** de bibliotecas quando possÃ­vel

## ğŸ“‹ Checklist de ExecuÃ§Ã£o

Para garantir execuÃ§Ã£o completa do trabalho:

- [ ] **Sistema verificado**: CPU cores e GPU disponÃ­vel
- [ ] **DependÃªncias instaladas**: `pip install -r requirements.txt`
- [ ] **GPU configurada** (se disponÃ­vel): CuPy instalado
- [ ] **Benchmark CPU executado**: `python matrix_cpu.py`
- [ ] **Benchmark GPU executado**: `python matrix_gpu.py` 
- [ ] **AnÃ¡lise completa**: `python matrix_comparison.py`
- [ ] **Resultados salvos**: CSVs e PNGs gerados
- [ ] **AnÃ¡lise interpretada**: Speedup e eficiÃªncia compreendidos

## ğŸ“š Conceitos AcadÃªmicos Demonstrados

### Teoria Aplicada
1. **Lei de Amdahl**: LimitaÃ§Ãµes teÃ³ricas do paralelismo observadas na CPU
2. **Escalabilidade**: Como performance varia com nÃºmero de threads e tamanho do problema
3. **Overhead Analysis**: Custos de paralelizaÃ§Ã£o e transferÃªncia GPU quantificados
4. **Break-even Analysis**: Ponto onde GPU supera CPU identificado empiricamente
5. **Memory vs Compute Bound**: Diferentes gargalos de performance analisados

### Paradigmas de ProgramaÃ§Ã£o Paralela
- **Shared Memory** (OpenMP-style): NumPy/BLAS threading
- **Distributed Memory** (MPI-style): Manual multiprocessing 
- **GPU Computing** (CUDA): Massively parallel acceleration
- **Hybrid Approaches**: Combinando mÃºltiplas tÃ©cnicas

### MÃ©tricas de Performance
- **Speedup**: S(n) = T(1) / T(n)
- **Efficiency**: E(n) = S(n) / n  
- **Scalability**: Comportamento com aumento de recursos
- **Throughput**: FLOPS (Floating Point Operations Per Second)

## ğŸ¯ AplicaÃ§Ãµes PrÃ¡ticas

Este benchmark Ã© relevante para:
- **Machine Learning**: Training de redes neurais
- **Scientific Computing**: SimulaÃ§Ãµes numÃ©ricas
- **Computer Graphics**: Processamento de imagens/vÃ­deo
- **Financial Modeling**: AnÃ¡lise de risco e pricing
- **Engineering**: AnÃ¡lise de elementos finitos

## ğŸ“ˆ VisualizaÃ§Ãµes IncluÃ­das

![Performance Comparison](complete_benchmark_results.png)
*ComparaÃ§Ã£o de performance entre diferentes configuraÃ§Ãµes*

![Scalability Analysis](scalability_analysis.png)  
*AnÃ¡lise de escalabilidade atravÃ©s de diferentes tamanhos de matriz*

---

## ğŸ“„ CitaÃ§Ã£o

Se este trabalho for Ãºtil para sua pesquisa, considere citar:

```bibtex
@misc{parallel_matrix_benchmark_2024,
  title={Parallel Matrix Benchmark: CPU vs GPU Performance Analysis},
  author={Academic Project},
  year={2024},
  url={https://github.com/bedimand/parallel-matrix-benchmark},
  note={RTX 3070 Ti CUDA acceleration study}
}
```

---

**Desenvolvido para:** *AceleraÃ§Ã£o em CiÃªncia de Dados usando ComputaÃ§Ã£o Paralela*  
**Hardware:** Intel CPU (20 cores) + NVIDIA RTX 3070 Ti  
**Com assistÃªncia de IA conforme diretrizes acadÃªmicas* 