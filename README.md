# ğŸš€ Parallel Matrix Benchmark: CPU vs GPU

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://python.org)
[![CUDA](https://img.shields.io/badge/CUDA-12.x-green.svg)](https://developer.nvidia.com/cuda-toolkit)
[![GPU](https://img.shields.io/badge/GPU-RTX%203070%20Ti-success.svg)](https://www.nvidia.com/en-us/geforce/graphics-cards/30-series/rtx-3070-ti/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

## ğŸ“‹ Sobre o Projeto

Este projeto implementa um **benchmark completo** para comparar o desempenho de processamento paralelo de matrizes entre diferentes configuraÃ§Ãµes de **CPU** e **GPU CUDA**. O estudo demonstra tÃ©cnicas de programaÃ§Ã£o paralela e analisa o ponto de break-even onde a aceleraÃ§Ã£o por GPU supera o processamento CPU tradicional.

**Desenvolvido como trabalho acadÃªmico para:** *AceleraÃ§Ã£o em CiÃªncia de Dados usando ComputaÃ§Ã£o Paralela*

### ğŸ† CaracterÃ­sticas do Estudo
- **AnÃ¡lise Completa**: CPU scaling (1-20 threads) vs GPU acceleration
- **Break-even Analysis**: Identifica quando GPU supera CPU
- **Hardware Real**: Testado com NVIDIA RTX 3070 Ti + CUDA 12.x
- **MÃºltiplos Tamanhos**: Matrizes de 1000Ã—1000 atÃ© 4000Ã—4000

## ğŸ¯ Objetivos

- **Aplicar conceitos de paralelismo** em arquiteturas CPU e GPU
- **Comparar paradigmas** de paralelismo de memÃ³ria compartilhada (OpenMP-like) vs aceleraÃ§Ã£o por GPU (CUDA)
- **Avaliar desempenho e escalabilidade** de diferentes configuraÃ§Ãµes
- **Demonstrar speedup e eficiÃªncia** com mÃ©tricas quantificÃ¡veis

## ğŸ—ï¸ Arquitetura do Projeto

```
Paralela/
â”œâ”€â”€ matrix_cpu.py              # Benchmark CPU (1, 2, 4, 8, todas threads)
â”œâ”€â”€ matrix_gpu.py              # Benchmark GPU (CuPy, Numba CUDA)
â”œâ”€â”€ matrix_comparison.py       # ComparaÃ§Ã£o completa CPU vs GPU
â”œâ”€â”€ requirements.txt           # DependÃªncias do projeto
â””â”€â”€ README.md                 # Este arquivo
```

## ğŸ“Š ConfiguraÃ§Ãµes Testadas

### CPU (Paralelismo de MemÃ³ria Compartilhada)
- **1 thread** (sequencial - baseline)
- **2 threads** 
- **4 threads**
- **8 threads**
- **Todas as threads** disponÃ­veis (20 no seu sistema)

### ImplementaÃ§Ãµes CPU
1. **NumPy Paralelo**: Usa bibliotecas otimizadas (BLAS/LAPACK) com controle de threads
2. **ParalelizaÃ§Ã£o Manual**: Divide matriz em chunks usando `multiprocessing`

### GPU (ComputaÃ§Ã£o Acelerada)
- **CuPy**: Biblioteca NumPy-like para GPU CUDA
- **Numba CUDA**: Kernels CUDA customizados em Python

## ğŸ› ï¸ InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

### 1. DependÃªncias BÃ¡sicas
```bash
pip install -r requirements.txt
```

### 2. DependÃªncias GPU (Opcional)
Para usar aceleraÃ§Ã£o GPU, instale CuPy conforme sua versÃ£o CUDA:

```bash
# Verificar versÃ£o CUDA
nvcc --version
nvidia-smi

# CUDA 12.x
pip install cupy-cuda12x

# CUDA 11.x  
pip install cupy-cuda11x

# Sem GPU (apenas para testes)
pip install cupy-cpu
```

### 3. Verificar Sistema
```bash
# CPU
python -c "import multiprocessing; print(f'CPU Cores: {multiprocessing.cpu_count()}')"

# GPU
nvidia-smi
```

## ğŸš€ Como Executar

### Teste RÃ¡pido
```bash
# Ativa ambiente virtual
source venv/bin/activate

# Executa anÃ¡lise completa
python matrix_comparison.py
```

### AnÃ¡lise de Escalabilidade (Recomendado)
```bash
# Testa diferentes tamanhos de matriz
python test_sizes.py
```

### Benchmarks Individuais

#### CPU (Threads: 1, 2, 4, 8, 20)
```bash
python matrix_cpu.py
```

#### GPU (CUDA)
```bash
python matrix_gpu.py
```

### ğŸ“Š Arquivos Gerados
- `complete_benchmark_results.csv/png`: ComparaÃ§Ã£o geral
- `scalability_analysis.png`: AnÃ¡lise de escalabilidade  
- `cpu_benchmark_results.csv/png`: Resultados CPU detalhados
- `gpu_benchmark_results.csv/png`: Resultados GPU

## ğŸ“ˆ MÃ©tricas Avaliadas

### Speedup
```
Speedup = Tempo_Sequencial / Tempo_Paralelo
```

### EficiÃªncia
```
EficiÃªncia = Speedup / NÃºmero_de_Threads
```

### AnÃ¡lises IncluÃ­das
- **Tempo de execuÃ§Ã£o** absoluto
- **Speedup** relativo ao baseline sequencial
- **EficiÃªncia** de paralelizaÃ§Ã£o
- **Escalabilidade** (anÃ¡lise de crescimento)
- **ComparaÃ§Ã£o CPU vs GPU** (total e apenas computaÃ§Ã£o)

## ğŸ“Š Resultados e AnÃ¡lises

### ğŸ“ˆ VisualizaÃ§Ãµes dos Benchmarks

Os resultados completos sÃ£o apresentados atravÃ©s de grÃ¡ficos interativos que mostram:

- **ComparaÃ§Ã£o de Performance**: Tempo de execuÃ§Ã£o por mÃ©todo
- **AnÃ¡lise de Break-even**: Ponto onde GPU supera CPU
- **Escalabilidade**: Performance atravÃ©s de diferentes tamanhos de matriz
- **Overhead Analysis**: Custos de transferÃªncia vs computaÃ§Ã£o

![Performance Comparison](complete_benchmark_results.png)
*ComparaÃ§Ã£o de performance entre diferentes configuraÃ§Ãµes*

![Scalability Analysis](scalability_analysis.png)  
*AnÃ¡lise de escalabilidade atravÃ©s de diferentes tamanhos de matriz*

### ğŸ” Insights Gerais

#### CaracterÃ­sticas CPU
- **Paralelismo eficiente**: NumPy/BLAS altamente otimizado
- **Sweet spot**: ConfiguraÃ§Ãµes de 4-8 threads
- **LimitaÃ§Ãµes**: Overhead significativo em paralelizaÃ§Ã£o manual

#### CaracterÃ­sticas GPU
- **Escalabilidade**: Vantagem cresce com tamanho do problema
- **Overhead crÃ­tico**: TransferÃªncia de dados impacta matrizes pequenas
- **Break-even**: Existe um ponto de transiÃ§Ã£o onde GPU supera CPU

#### Descobertas Importantes
1. **Break-even analysis**: GPU nÃ£o Ã© sempre superior - depende do tamanho do problema
2. **Biblioteca optimization**: NumPy/BLAS compete surpreendentemente bem com GPU
3. **Transfer overhead**: Fator crÃ­tico para determinar viabilidade da aceleraÃ§Ã£o GPU
4. **Scaling behavior**: GPU demonstra melhor escalabilidade para problemas grandes

## ğŸ”§ ConfiguraÃ§Ãµes PersonalizÃ¡veis

### Tamanho da Matriz
```python
# No cÃ³digo, modifique:
processor = MatrixProcessorCPU(matrix_size=1000)  # Para 1000x1000
processor = MatrixProcessorGPU(matrix_size=4000)  # Para 4000x4000
```

### Threads a Testar
```python
# Em matrix_cpu.py, linha ~116:
thread_configs = [1, 2, 4, 8, 16, 32]  # Personalize aqui
```

## ğŸ“ Alinhamento com Trabalho AcadÃªmico

Este projeto atende perfeitamente aos requisitos do trabalho:

### âœ… Conceitos Explorados
- **MPI-like**: ParalelizaÃ§Ã£o manual com `multiprocessing`
- **OpenMP-like**: Controle de threads NumPy/BLAS
- **CUDA**: AceleraÃ§Ã£o GPU com CuPy e Numba

### âœ… Objetivos Atendidos
- **AplicaÃ§Ã£o de paralelismo**: âœ… MÃºltiplas implementaÃ§Ãµes
- **DiferenciaÃ§Ã£o de paradigmas**: âœ… CPU vs GPU claramente separados
- **ImplementaÃ§Ã£o GPU**: âœ… CuPy e Numba CUDA
- **AvaliaÃ§Ã£o de desempenho**: âœ… MÃ©tricas quantificÃ¡veis
- **Uso de IA**: âœ… Documentado neste README

### âœ… Deliverables
- **CÃ³digo fonte**: âœ… TrÃªs arquivos principais bem documentados
- **AnÃ¡lise de desempenho**: âœ… CSV e grÃ¡ficos automÃ¡ticos
- **ComparaÃ§Ã£o**: âœ… Sequencial vs paralelo vs GPU
- **DocumentaÃ§Ã£o**: âœ… README completo

## ğŸ¤– Uso de IA no Projeto

Este projeto foi desenvolvido com assistÃªncia significativa de IA (Claude/ChatGPT) nas seguintes Ã¡reas:

### AssistÃªncia de CÃ³digo
- **EstruturaÃ§Ã£o das classes** e organizaÃ§Ã£o modular
- **ImplementaÃ§Ã£o de benchmarks** e mediÃ§Ã£o de tempo
- **IntegraÃ§Ã£o CUDA** com CuPy e Numba

### OtimizaÃ§Ã£o e Boas PrÃ¡ticas
- **Tratamento de erros** e verificaÃ§Ã£o de disponibilidade GPU
- **VisualizaÃ§Ãµes** com matplotlib e anÃ¡lise estatÃ­stica
- **DocumentaÃ§Ã£o** e comentÃ¡rios explicativos

### Debugging e ValidaÃ§Ã£o
- **InstalaÃ§Ã£o automÃ¡tica** de bibliotecas quando possÃ­vel

## ğŸ“‹ Checklist de ExecuÃ§Ã£o

Para garantir execuÃ§Ã£o completa do trabalho:

- [ ] **Sistema verificado**: CPU cores e GPU disponÃ­vel
- [ ] **DependÃªncias instaladas**: `pip install -r requirements.txt`
- [ ] **GPU configurada** (se disponÃ­vel): CuPy instalado
- [ ] **Benchmark CPU executado**: `python matrix_cpu.py`
- [ ] **Benchmark GPU executado**: `python matrix_gpu.py` 
- [ ] **AnÃ¡lise completa**: `python matrix_comparison.py`
- [ ] **Resultados salvos**: CSVs e PNGs gerados
- [ ] **AnÃ¡lise interpretada**: Speedup e eficiÃªncia compreendidos

## ğŸ“š Conceitos AcadÃªmicos Demonstrados

### Teoria Aplicada
1. **Lei de Amdahl**: LimitaÃ§Ãµes teÃ³ricas do paralelismo observadas na CPU
2. **Escalabilidade**: Como performance varia com nÃºmero de threads e tamanho do problema
3. **Overhead Analysis**: Custos de paralelizaÃ§Ã£o e transferÃªncia GPU quantificados
4. **Break-even Analysis**: Ponto onde GPU supera CPU identificado empiricamente
5. **Memory vs Compute Bound**: Diferentes gargalos de performance analisados

### Paradigmas de ProgramaÃ§Ã£o Paralela
- **Shared Memory** (OpenMP-style): NumPy/BLAS threading
- **Distributed Memory** (MPI-style): Manual multiprocessing 
- **GPU Computing** (CUDA): Massively parallel acceleration
- **Hybrid Approaches**: Combinando mÃºltiplas tÃ©cnicas

### MÃ©tricas de Performance
- **Speedup**: S(n) = T(1) / T(n)
- **Efficiency**: E(n) = S(n) / n  
- **Scalability**: Comportamento com aumento de recursos
- **Throughput**: FLOPS (Floating Point Operations Per Second)

## ğŸ¯ AplicaÃ§Ãµes PrÃ¡ticas

Este benchmark Ã© relevante para:
- **Machine Learning**: Training de redes neurais
- **Scientific Computing**: SimulaÃ§Ãµes numÃ©ricas
- **Computer Graphics**: Processamento de imagens/vÃ­deo
- **Financial Modeling**: AnÃ¡lise de risco e pricing
- **Engineering**: AnÃ¡lise de elementos finitos

---

**Desenvolvido para:** *AceleraÃ§Ã£o em CiÃªncia de Dados usando ComputaÃ§Ã£o Paralela*  
**Hardware:** Intel CPU (20 cores) + NVIDIA RTX 3070 Ti  
**Com assistÃªncia de IA conforme diretrizes acadÃªmicas* 
