# Processamento Paralelo de Matrizes - CPU vs GPU

## ğŸ“‹ Sobre o Projeto

Este projeto implementa um benchmark completo para comparar o desempenho de processamento paralelo de matrizes entre diferentes configuraÃ§Ãµes de CPU e GPU CUDA. Foi desenvolvido como parte do trabalho de **AceleraÃ§Ã£o em CiÃªncia de Dados usando ComputaÃ§Ã£o Paralela**.

## ğŸ¯ Objetivos

- **Aplicar conceitos de paralelismo** em arquiteturas CPU e GPU
- **Comparar paradigmas** de paralelismo de memÃ³ria compartilhada (OpenMP-like) vs aceleraÃ§Ã£o por GPU (CUDA)
- **Avaliar desempenho e escalabilidade** de diferentes configuraÃ§Ãµes
- **Demonstrar speedup e eficiÃªncia** com mÃ©tricas quantificÃ¡veis

## ğŸ—ï¸ Arquitetura do Projeto

```
Paralela/
â”œâ”€â”€ matrix_cpu.py              # Benchmark CPU (1, 2, 4, 8, todas threads)
â”œâ”€â”€ matrix_gpu.py              # Benchmark GPU (CuPy, Numba CUDA)
â”œâ”€â”€ matrix_comparison.py       # ComparaÃ§Ã£o completa CPU vs GPU
â”œâ”€â”€ requirements.txt           # DependÃªncias do projeto
â””â”€â”€ README.md                 # Este arquivo
```

## ğŸ“Š ConfiguraÃ§Ãµes Testadas

### CPU (Paralelismo de MemÃ³ria Compartilhada)
- **1 thread** (sequencial - baseline)
- **2 threads** 
- **4 threads**
- **8 threads**
- **Todas as threads** disponÃ­veis (20 no seu sistema)

### ImplementaÃ§Ãµes CPU
1. **NumPy Paralelo**: Usa bibliotecas otimizadas (BLAS/LAPACK) com controle de threads
2. **ParalelizaÃ§Ã£o Manual**: Divide matriz em chunks usando `multiprocessing`

### GPU (ComputaÃ§Ã£o Acelerada)
- **CuPy**: Biblioteca NumPy-like para GPU CUDA
- **Numba CUDA**: Kernels CUDA customizados em Python

## ğŸ› ï¸ InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

### 1. DependÃªncias BÃ¡sicas
```bash
pip install -r requirements.txt
```

### 2. DependÃªncias GPU (Opcional)
Para usar aceleraÃ§Ã£o GPU, instale CuPy conforme sua versÃ£o CUDA:

```bash
# Verificar versÃ£o CUDA
nvcc --version
nvidia-smi

# CUDA 12.x
pip install cupy-cuda12x

# CUDA 11.x  
pip install cupy-cuda11x

# Sem GPU (apenas para testes)
pip install cupy-cpu
```

### 3. Verificar Sistema
```bash
# CPU
python -c "import multiprocessing; print(f'CPU Cores: {multiprocessing.cpu_count()}')"

# GPU
nvidia-smi
```

## ğŸš€ Como Executar

### Benchmark Individual CPU
```bash
python matrix_cpu.py
```
**SaÃ­da:**
- `cpu_benchmark_results.csv`: Dados tabulados
- `cpu_benchmark_results.png`: GrÃ¡ficos de desempenho

### Benchmark Individual GPU
```bash
python matrix_gpu.py
```
**SaÃ­da:**
- `gpu_benchmark_results.csv`: Dados de comparaÃ§Ã£o CPU vs GPU
- `gpu_benchmark_results.png`: VisualizaÃ§Ãµes

### Benchmark Completo (Recomendado)
```bash
python matrix_comparison.py
```
**SaÃ­da:**
- `complete_benchmark_results.csv`: Todos os resultados
- `complete_benchmark_results.png`: AnÃ¡lise visual completa

## ğŸ“ˆ MÃ©tricas Avaliadas

### Speedup
```
Speedup = Tempo_Sequencial / Tempo_Paralelo
```

### EficiÃªncia
```
EficiÃªncia = Speedup / NÃºmero_de_Threads
```

### AnÃ¡lises IncluÃ­das
- **Tempo de execuÃ§Ã£o** absoluto
- **Speedup** relativo ao baseline sequencial
- **EficiÃªncia** de paralelizaÃ§Ã£o
- **Escalabilidade** (anÃ¡lise de crescimento)
- **ComparaÃ§Ã£o CPU vs GPU** (total e apenas computaÃ§Ã£o)

## ğŸ“Š Resultados Esperados

### CPU
- **Speedup ideal**: Linear atÃ© limite fÃ­sico de cores
- **EficiÃªncia decrescente**: Devido a overhead e contenÃ§Ã£o de memÃ³ria
- **Melhor configuraÃ§Ã£o**: Geralmente entre 4-8 threads para matrizes 2000x2000

### GPU
- **Alto speedup**: 10x-100x+ para computaÃ§Ã£o pura
- **Overhead de transferÃªncia**: Reduz speedup total
- **Vantagem**: Maior para operaÃ§Ãµes intensivas em ponto flutuante

## ğŸ”§ ConfiguraÃ§Ãµes PersonalizÃ¡veis

### Tamanho da Matriz
```python
# No cÃ³digo, modifique:
processor = MatrixProcessorCPU(matrix_size=1000)  # Para 1000x1000
processor = MatrixProcessorGPU(matrix_size=4000)  # Para 4000x4000
```

### Threads a Testar
```python
# Em matrix_cpu.py, linha ~116:
thread_configs = [1, 2, 4, 8, 16, 32]  # Personalize aqui
```

## ğŸ“ Alinhamento com Trabalho AcadÃªmico

Este projeto atende perfeitamente aos requisitos do trabalho:

### âœ… Conceitos Explorados
- **MPI-like**: ParalelizaÃ§Ã£o manual com `multiprocessing`
- **OpenMP-like**: Controle de threads NumPy/BLAS
- **CUDA**: AceleraÃ§Ã£o GPU com CuPy e Numba

### âœ… Objetivos Atendidos
- **AplicaÃ§Ã£o de paralelismo**: âœ… MÃºltiplas implementaÃ§Ãµes
- **DiferenciaÃ§Ã£o de paradigmas**: âœ… CPU vs GPU claramente separados
- **ImplementaÃ§Ã£o GPU**: âœ… CuPy e Numba CUDA
- **AvaliaÃ§Ã£o de desempenho**: âœ… MÃ©tricas quantificÃ¡veis
- **Uso de IA**: âœ… Documentado neste README

### âœ… Deliverables
- **CÃ³digo fonte**: âœ… TrÃªs arquivos principais bem documentados
- **AnÃ¡lise de desempenho**: âœ… CSV e grÃ¡ficos automÃ¡ticos
- **ComparaÃ§Ã£o**: âœ… Sequencial vs paralelo vs GPU
- **DocumentaÃ§Ã£o**: âœ… README completo

## ğŸ¤– Uso de IA no Projeto

Este projeto foi desenvolvido com assistÃªncia significativa de IA (Claude/ChatGPT) nas seguintes Ã¡reas:

### AssistÃªncia de CÃ³digo
- **EstruturaÃ§Ã£o das classes** e organizaÃ§Ã£o modular
- **ImplementaÃ§Ã£o de benchmarks** e mediÃ§Ã£o de tempo
- **ParalelizaÃ§Ã£o manual** com multiprocessing
- **IntegraÃ§Ã£o CUDA** com CuPy e Numba

### OtimizaÃ§Ã£o e Boas PrÃ¡ticas
- **Controle de threads** via variÃ¡veis de ambiente
- **Tratamento de erros** e verificaÃ§Ã£o de disponibilidade GPU
- **VisualizaÃ§Ãµes** com matplotlib e anÃ¡lise estatÃ­stica
- **DocumentaÃ§Ã£o** e comentÃ¡rios explicativos

### Debugging e ValidaÃ§Ã£o
- **VerificaÃ§Ã£o de consistÃªncia** entre resultados CPU e GPU
- **Tratamento de dependÃªncias** opcionais
- **InstalaÃ§Ã£o automÃ¡tica** de bibliotecas quando possÃ­vel

## ğŸ“‹ Checklist de ExecuÃ§Ã£o

Para garantir execuÃ§Ã£o completa do trabalho:

- [ ] **Sistema verificado**: CPU cores e GPU disponÃ­vel
- [ ] **DependÃªncias instaladas**: `pip install -r requirements.txt`
- [ ] **GPU configurada** (se disponÃ­vel): CuPy instalado
- [ ] **Benchmark CPU executado**: `python matrix_cpu.py`
- [ ] **Benchmark GPU executado**: `python matrix_gpu.py` 
- [ ] **AnÃ¡lise completa**: `python matrix_comparison.py`
- [ ] **Resultados salvos**: CSVs e PNGs gerados
- [ ] **AnÃ¡lise interpretada**: Speedup e eficiÃªncia compreendidos

## ğŸ“š Conceitos AcadÃªmicos Demonstrados

1. **Lei de Amdahl**: LimitaÃ§Ãµes teÃ³ricas do paralelismo
2. **Escalabilidade**: Como performance varia com recursos
3. **Overhead**: Custos de paralelizaÃ§Ã£o e transferÃªncia GPU
4. **EficiÃªncia EnergÃ©tica**: GPU vs CPU para operaÃ§Ãµes massivas
5. **Memory Bound vs Compute Bound**: Diferentes gargalos de performance

---

**Desenvolvido para o curso de AceleraÃ§Ã£o em CiÃªncia de Dados usando ComputaÃ§Ã£o Paralela**  
*Com assistÃªncia de IA conforme diretrizes do trabalho* 